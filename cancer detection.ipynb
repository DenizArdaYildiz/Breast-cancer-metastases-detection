{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import StepLR\nimport torch.optim as optim\nimport pandas as pd \nCFG = {\n    \"batch_size\": 32,\n    \"epoch\": 10,\n    \"log_interval\": 100,\n}","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-06T14:27:45.783390Z","iopub.execute_input":"2023-01-06T14:27:45.784027Z","iopub.status.idle":"2023-01-06T14:27:45.790450Z","shell.execute_reply.started":"2023-01-06T14:27:45.783957Z","shell.execute_reply":"2023-01-06T14:27:45.789450Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom torchvision.io import read_image\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nimport numpy as np\npreprocess_transform = transforms.Compose([\n    transforms.ToTensor(), # turn image to tensor\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    # augmentations\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(5),\n    transforms.RandomResizedCrop(128),\n\n    transforms.Resize((512,512))\n])\n\nval_transform = transforms.Compose([\n    transforms.ToTensor(), # turn image to tensor\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    transforms.Resize((512,512))\n])\nclass CustomImageDataset(Dataset):\n    def init(self, df, img_dir, transform=None):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n\n\n    def len(self):\n        return len(self.df)\n\n    def getitem(self, idx):\n        img_path = os.path.join(self.img_dir, self.df.iloc[idx,0]+ \".jpeg\")\n\n        image = Image.open(img_path)\n        image = np.array(image)\n        label = self.df.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\ndf = pd.read_csv('/kaggle/input/bau-ain2001-fall22-a3p1/train.csv')\n\nfrom sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n\ntrain_set = CustomImageDataset(train_df, img_dir='/kaggle/input/bau-ain2001-fall22-a3p1/images/images',transform=preprocess_transform)\nval_set = CustomImageDataset(val_df, img_dir='/kaggle/input/bau-ain2001-fall22-a3p1/images/images',transform=val_transform)\n\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True)\ntest_loader = DataLoader(val_set, batch_size=32, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-06T14:27:45.792696Z","iopub.execute_input":"2023-01-06T14:27:45.793286Z","iopub.status.idle":"2023-01-06T14:27:45.834685Z","shell.execute_reply.started":"2023-01-06T14:27:45.793235Z","shell.execute_reply":"2023-01-06T14:27:45.833255Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2404697263.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/input/bau-ain2001-fall22-a3p1/images/images'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/kaggle/input/bau-ain2001-fall22-a3p1/images/images'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/typing.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwds)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object.__new__() takes exactly one argument (the type to instantiate)"],"ename":"TypeError","evalue":"object.__new__() takes exactly one argument (the type to instantiate)","output_type":"error"}]},{"cell_type":"code","source":"class Net(nn.Module):\n    def init(self):\n        super(Net, self).init()\n        # 512 x 512 x 3\n        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n        # 510 x 510 x 32\n        self.conv2 = nn.Conv2d(32, 2, 3, 1)\n        # 508 x 508 x 64\n        self.dropout = nn.Dropout(0.25)\n        # after maxpooling and flattening we got (batch x 32258 )\n        self.fc1 = nn.Linear(32258, 128)\n        self.fc2 = nn.Linear(128, 1)\n        self.activation = nn.LeakyReLU()\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x= self.activation(x)\n        x = self.conv2(x)\n        x= self.activation(x)\n        x = F.max_pool2d(x, 2)\n        x= self.activation(x)\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x= self.activation(x)\n        x = self.fc2(x)\n        output = torch.sigmoid(x)\n        output = torch.reshape(output, (x.shape[0],))\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-01-06T14:27:45.835715Z","iopub.status.idle":"2023-01-06T14:27:45.836797Z","shell.execute_reply.started":"2023-01-06T14:27:45.836524Z","shell.execute_reply":"2023-01-06T14:27:45.836554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\ndef train(model, train_loader, optimizer, epoch, criterion):\n    model.train()\n\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output.float(), target.float())\n        loss.backward()\n        optimizer.step()\n        if batch_idx % CFG['log_interval'] == 0:\n            print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n\ndef test(model, test_loader, criterion):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += criterion(output.float(), target.float()).item()\n            pred = output.float()\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset) / CFG['batch_size']\n    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))","metadata":{"execution":{"iopub.status.busy":"2023-01-06T14:27:45.838318Z","iopub.status.idle":"2023-01-06T14:27:45.838812Z","shell.execute_reply.started":"2023-01-06T14:27:45.838567Z","shell.execute_reply":"2023-01-06T14:27:45.838591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Net().to(device)\ncriterion = nn.BCELoss()\n# adam\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nfor epoch in range(CFG[\"epoch\"]):  # loop over the dataset multiple times\n    train(model, train_loader, optimizer, epoch, criterion)\n    test(model, test_loader, criterion)\n\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2023-01-06T14:27:45.840445Z","iopub.status.idle":"2023-01-06T14:27:45.840955Z","shell.execute_reply.started":"2023-01-06T14:27:45.840676Z","shell.execute_reply":"2023-01-06T14:27:45.840698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Net().to(device)\ncriterion = nn.BCELoss()\n# adam\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nfor epoch in range(CFG[\"epoch\"]):  # loop over the dataset multiple times\n    train(model, train_loader, optimizer, epoch, criterion)\n    test(model, test_loader, criterion)\n\n\nprint('Finished Training')\nclass TestDataset(Dataset):\n    def init(self, df, img_dir, transform=None):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def len(self):\n        return len(self.df)\n\n    def getitem(self, idx):\n        img_path = os.path.join(self.img_dir, self.df.iloc[idx,0]+ \".jpeg\")\n        image = Image.open(img_path)\n        image = np.array(image)\n        if self.transform:\n            image = self.transform(image)\n        return image\n\n\n\ntest_df = pd.read_csv('/kaggle/input/bau-ain2001-fall22-a3p1/test.csv')\ntest_set = TestDataset(test_df, img_dir='/kaggle/input/bau-ain2001-fall22-a3p1/images/images',transform=val_transform)\ntest_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n\nmodel.eval()\npreds = []\nwith torch.no_grad():\n    for data in test_loader:\n        data = data.to(device)\n        output = model(data)\n        preds.extend(output.cpu().numpy().tolist())\n\ntest_df['cancer_score'] = preds\n\n# image id and cancer score\ntest_df = test_df[['img_id', 'cancer_score']]\ntest_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-06T14:27:45.842973Z","iopub.status.idle":"2023-01-06T14:27:45.843458Z","shell.execute_reply.started":"2023-01-06T14:27:45.843200Z","shell.execute_reply":"2023-01-06T14:27:45.843223Z"},"trusted":true},"execution_count":null,"outputs":[]}]}